# Information

https://en.wikipedia.org/wiki/Information

Information may be thought of as the resolution of some uncertainty; it is that which answers the question of "what something is" and thus defines both its essential nature of characteristics.

The concept of information has different meanings in different contexts, thus being related to notions that include constraint, communication, control, data, form, education, knowledge, meaning, understanding, (mental) stimuli, pattern, perception, representation, entropy.

Information is associated with data, as data represents values attributed to parameters.

> Information is data within a context, with some meaning attached.

In terms of communication, information is expressed as the *content of a message*. Information is also obtained through direct or indirect observation. Perceived content may be considered as a message in its own right, so in that sense, information is always conveyed as the content of a message (whether observed or communicated).

**Information encoding**. Information may be encoded into various forms for transmission and interpretation (e.g. information may be encoded into a sequence of signs, or transmitted via a signal). Information is encrypted for consumation or for storage and long-term archiving.

The *uncertainty of an event* is measured by its probability of occurrence and is inversely proportional to that. The more uncertain an event, the more information is required to resolve uncertainty of that event.

The *bit* is a typical unit of information, but other units such as the *nat* may be used. For example, the information encoded in one "fair" coin flip is log2(2/1) = 1 bit, and in two coin flips it is log2(4/1) = 2 bits.



---


In 1948, Claude Shannon proposed a model for communications over the telephone, a model expanded by Warren Weaver in 1949, showing that Shannon's model applies to any communication system.

The *Shannon/Weaver model* shows that the data transmission systems should consist of 6 components:
- Sender (or source) that transmits the message.
- Encoder to encode the message.
- Message itself.
- Channel (or medium) through which the message is transmitted.
- Decoder to decode the message.
- Receiver (or destination) as the intended receiver of the message.


**Unit of information** is the capacity of a data storage system (or communication channel), used to measure the capacities of other systems.

**Bit**, the funamental unit of information, is the capacity of a system that has only 2 states. **Binary digits** are concrete symbols (i.e. 1 and 0) that can be placed in a bit. The name "bit" is portmanteau of "binary digit", but they are not the same: a bit is the maximum amount of information that can be conveyed by a binary digit.

One bit is typically defined as the information entropy of a random binary variable that is 0 or 1 with equal probability, or the information that is gained when the value of such variable is consumed (i.e. when the value becomes known).



## References

https://en.wikipedia.org/wiki/Information_science
https://en.wikipedia.org/wiki/Information_theory
https://en.wikipedia.org/wiki/Information_technology

https://en.wikipedia.org/wiki/Information_(disambiguation)
https://en.wikipedia.org/wiki/Information_entropy
https://en.wikipedia.org/wiki/Nat_(unit)
